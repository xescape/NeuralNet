{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this one I'm hoping to graph out all the layers, hopefully to prove that all\n",
    "the trained models focus on a couple of specific features. We'll leave identifying\n",
    "the relevant features to maybe a different one? Or maybe it'll just happen near the end.\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "from multiprocessing import Pool\n",
    "import statsmodels\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "working_dir = Path('/d/data/plasmo/training_data/output_new')\n",
    "# input_file = working_dir / 'saved_model0.h5'\n",
    "data_file = working_dir / 'data.tsv'\n",
    "meta_file = working_dir / 'meta.tsv'\n",
    "id_file = working_dir / 'prefilter.tsv'\n",
    "out_file = working_dir / 'predicted_genes_full.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                6976      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 8,033\n",
      "Trainable params: 8,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_models = 10\n",
    "models = [tf.keras.models.load_model((working_dir / 'saved_model{0}.h5'.format(n))) for n in range(n_models)]\n",
    "    \n",
    "\n",
    "# model1 = tf.keras.models.load_model(input_file)\n",
    "data = np.loadtxt(data_file)\n",
    "meta = np.loadtxt(meta_file)\n",
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get linear models\n",
    "# from sklearn.linear_model import LassoLarsCV, LassoLars\n",
    "# model = LassoLars(alpha=0.001)\n",
    "# model.fit(data, meta.reshape((meta.shape[0],)))\n",
    "\n",
    "# abs_coefs = np.abs(model.coef_) * (np.sum(data, axis=0) > (data.shape[0] * 0.05))\n",
    "# sorted_index = np.argsort(abs_coefs)\n",
    "# good_idx = sorted_index[(-1 * int(np.count_nonzero(abs_coefs) * 0.2)):]\n",
    "\n",
    "# id_df = pd.read_csv(id_file, sep='\\t')\n",
    "# prediction_df = pd.DataFrame({'idx': good_idx,\n",
    "#                               'id': id_df.loc[good_idx, 'id'],\n",
    "#                               'average_impact': model.coef_[good_idx],\n",
    "#                               'abs_impact': abs_coefs[good_idx]})\n",
    "# prediction_df.set_index('idx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(108, 64), (64,), (64, 16), (16,), (16, 1), (1,)]\n"
     ]
    }
   ],
   "source": [
    "weights = models[0].get_weights()\n",
    "print([x.shape for x in weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reshapeForPlot(matrix):\n",
    "#     #makes a df out of the matrix where each line is a point\n",
    "#     width, height = matrix.shape\n",
    "#     x_list = [x for x in range(width) for y in range(height)]\n",
    "#     y_list = [y for x in range(width) for y in range(height)]\n",
    "#     z_list = [matrix[x,y] for x in range(width) for y in range(height)]\n",
    "#     return pd.DataFrame({'features': x_list, 'neurons':y_list, 'val': z_list})\n",
    "\n",
    "# for x in range(0, len(weights), 2):\n",
    "#     layer_weights = reshapeForPlot(weights[x])\n",
    "#     bias_weights = pd.DataFrame({'neurons': range(weights[x+1].shape[0]), 'vals':weights[x+1]})\n",
    "    \n",
    "#     bias_text_y_delta = (np.max(weights[x+1]) - np.min(weights[x+1])) / 100\n",
    "#     bias_text_x_delta = weights[x+1].shape[0] / 60\n",
    "    \n",
    "#     layer_plot = (ggplot(layer_weights, aes('features', 'neurons', fill='val'))\n",
    "#                 + geom_tile(aes(width=.95, height=.95))\n",
    "#                 )\n",
    "#     bias_plot = (ggplot(bias_weights, aes('neurons', 'vals'))\n",
    "#              + geom_point()\n",
    "#              + geom_text(aes(label='neurons'), size=5, nudge_x=0.1, nudge_y=-0.01))\n",
    "    \n",
    "#     layer_plot.draw()\n",
    "#     layer_plot.save(working_dir / 'layer_{0}_weights.pdf'.format(int(np.ceil(x/2))), dpi=300, width=8, height=6, units='in')\n",
    "\n",
    "#     bias_plot.draw()\n",
    "#     bias_plot.save(working_dir / 'layer_{0}_bias.pdf'.format(int(np.ceil(x/2))), dpi=300, width=8, height=6, units='in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay we're just doing the prediction here\n",
    "#so the highest numbers in impact will be the selected vals\n",
    "\n",
    "def makeModSamples(sample):\n",
    "    n_features = sample.shape[0]\n",
    "    base = np.tile(sample, (n_features, 1)) #the same one repeated\n",
    "    msk = np.zeros_like(base)\n",
    "    for x in range(n_features):\n",
    "        if base[x][x] > 0:\n",
    "            base[x][x] = 0\n",
    "            msk[x,:] = 1\n",
    "\n",
    "    return np.array([base, msk]) #returns a 3D array\n",
    "    \n",
    "\n",
    "def getPredictions(model):\n",
    "    \n",
    "    def apply_fn(arr): #receives a 3D array generated by makeModSamples and reduces to two, then predict\n",
    "        preds = model.predict(arr[0])\n",
    "        return preds.reshape(-1,) * arr[1,:,0]\n",
    "\n",
    "    #here we are only counting ones above bound\n",
    "    def my_relu(n, bound):\n",
    "        if n > bound:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    #turn 1s to 0s\n",
    "    mod = np.apply_along_axis(makeModSamples, 1, data)\n",
    "    mod_preds = np.array([apply_fn(x) for x in mod]) #result should be a 2D array of samples x features\n",
    "    original_preds = model.predict(data)\n",
    "    counts = np.sum(data, axis=0)\n",
    "    \n",
    "#     print(original_preds, mod_preds)\n",
    "#     diffs = np.absolute(((mod_preds - original_preds) * (mod_preds > 0)))\n",
    "    #given that we have modded values, I'm going to try non-abs values.\n",
    "    diffs = (original_preds - mod_preds) * (np.absolute(mod_preds) > 0)\n",
    "    total_diffs = np.sum(diffs, axis=0)\n",
    "    avg_diffs = total_diffs / counts\n",
    "    \n",
    "#     print(diffs.shape, avg_diffs.shape)\n",
    "    \n",
    "    #we care about counts up to a point\n",
    "    \n",
    "    n_samples = data.shape[0]\n",
    "    bound = int(n_samples * 0.05) #that point being 5% of all samples\n",
    "#     bound = 5\n",
    "    count_modifier = np.array([my_relu(x, bound) for x in counts])\n",
    "    \n",
    "#     print(count_modifier.shape)\n",
    "    res = avg_diffs * count_modifier #this one gave the good results\n",
    "#     res = avg_diffs #here we're applying the count modifier later\n",
    "    \n",
    "#     res = np.sum(diffs, axis=0) * count_modifier\n",
    "#     print(count_modifier)\n",
    "\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this is an alternative method where we try to emulate the mistake we made before\n",
    "# #by just adding up the cases were a feature = 1\n",
    "\n",
    "# def makeModSamples(sample):\n",
    "#     n_features = sample.shape[0]\n",
    "#     base = np.tile(sample, (n_features, 1)) #the same one repeated\n",
    "#     msk = np.zeros_like(base)\n",
    "#     for x in range(n_features):\n",
    "#         if base[x][x] > 0:\n",
    "#             base[x][x] = 0\n",
    "#             msk[x,:] = 1\n",
    "\n",
    "#     return np.array([base, msk]) #returns a 3D array\n",
    "    \n",
    "\n",
    "# def getPredictions(model):\n",
    "    \n",
    "#     def apply_fn(arr): #receives a 3D array generated by makeModSamples and reduces to two, then predict\n",
    "#         preds = model.predict(arr[0])\n",
    "#         return preds.reshape(-1,) * arr[1,:,0]\n",
    "\n",
    "#     #here we are only counting ones above bound\n",
    "#     def my_relu(n, bound):\n",
    "#         if n > bound:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "    \n",
    "#     #turn 1s to 0s\n",
    "# #     mod = np.apply_along_axis(makeModSamples, 1, data)\n",
    "# #     mod_preds = np.array([apply_fn(x) for x in mod]) #result should be a 2D array of samples x features\n",
    "#     original_preds = model.predict(data)\n",
    "#     counts = np.sum(data, axis=0)\n",
    "    \n",
    "# #     print(original_preds, mod_preds)\n",
    "# #     diffs = np.absolute(((mod_preds - original_preds) * (mod_preds > 0)))\n",
    "#     #given that we have modded values, I'm going to try non-abs values.\n",
    "# #     diffs = (original_preds - mod_preds) * data\n",
    "# #     total_diffs = np.sum(diffs, axis=0)\n",
    "# #     avg_diffs = total_diffs / counts\n",
    "\n",
    "#     n_samples = data.shape[0]\n",
    "#     bound = n_samples * 0.05 #that point being 5% of all samples\n",
    "# #     bound = 5\n",
    "#     count_modifier = np.sum(data, axis=0) > bound\n",
    "\n",
    "#     sums = np.sum((original_preds * data), axis=0) / counts * count_modifier\n",
    "    \n",
    "# #     sums = original_preds * (mod_pre)\n",
    "    \n",
    "#     return sums\n",
    "\n",
    "# # m = models[0]\n",
    "# # s = getPredictions(m)\n",
    "# # print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.loadtxt(data_file)\n",
    "# pred_res = getPredictions(model1)\n",
    "# print(np.argsort(pred_res)[:-10:-1])\n",
    "# # np.absolute((np.array([[1,2,3,4], [5,6,7,8]]) - np.array([9,9,9,9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.argsort(pred_res)[:-50:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_lists = []\n",
    "for m in models:\n",
    "    impact_lists.append(getPredictions(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_lists = [np.absolute(x) for x in impact_lists]\n",
    "ind_lists = [np.argsort(x)[::-1] for x in abs_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hits = int(np.count_nonzero(impact_lists[0]) * 0.2) #we take top 20%\n",
    "top_hits = [np.sort(x[:n_hits]) for x in ind_lists]\n",
    "\n",
    "# #in this case we're saying top 20% of all hits, and more than 5% representation\n",
    "# n_min = data.shape[0] * 0.05\n",
    "# features_to_use = np.argwhere(np.sum(data, axis=0) > n_min).reshape(-1,)\n",
    "# top_hits_filtered = [np.intersect1d(hits, features_to_use) for hits in top_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "14\n",
      "[  2.  23.  96.   6.  14.   6.   8.  80.  28.   2.   4.   4.  37.   4.\n",
      "  14.   4.   4.   3.   9.  54.   7.  13.  19.  39.  17.  10.   5.   7.\n",
      "   8.   5.  42.   5.  27.  48.  22.  58.   8.  17. 113.  17.  95.  21.\n",
      "  23.  19.  19.  20.   8.   5.   5.  21.   2.  17. 110.   3. 135. 103.\n",
      "  28.  35.   4.  39. 132.   5.  79.  24.  67.   7.   8.  42.   4.  12.\n",
      "  17.  17.   6.  27.   5.  67.   5.  33.   4.   9.  26.  11.   7.  23.\n",
      "  23.   8.  78.  77.  26.   4.  11.   7.  23.  94.  24.   5.  99.   5.\n",
      "   8.  18.   7.   7.   3.   3.   5.  18.  10.  53.]\n"
     ]
    }
   ],
   "source": [
    "#We're looking for an intersection between three models\n",
    "common_inds = np.intersect1d(top_hits[0], top_hits[1])\n",
    "for x in top_hits[2:]:\n",
    "    common_inds = np.intersect1d(common_inds, x)\n",
    "common_inds = np.sort(common_inds)\n",
    "\n",
    "###DELETE AFTER, this part skips the intersection and lists everything\n",
    "# common_inds = [np.sort(x[:np.count_nonzero(impact_lists[0])]) for x in ind_lists][0]\n",
    "###\n",
    "# ind_list_sorted = np.matrix([np.sort(x) for x in ind_list], dtype=np.int32)\n",
    "# print(str(ind_list_sorted))\n",
    "\n",
    "average_impact = np.average([x[common_inds] for x in impact_lists], axis = 0)\n",
    "print(len(common_inds))\n",
    "print(n_hits)\n",
    "print(np.sum(data, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.read_csv(id_file, sep='\\t')\n",
    "prediction_df = pd.DataFrame({'idx': common_inds,\n",
    "                              'id': id_df.loc[common_inds, 'id'],\n",
    "                              'average_impact': average_impact,\n",
    "                              'abs_impact': np.absolute(average_impact)})\n",
    "for x in range(n_models):\n",
    "    prediction_df['model_{0}'.format(x)] = impact_lists[x][common_inds]\n",
    "prediction_df.set_index('idx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def doTTest(idx):\n",
    "#     test_df = pd.DataFrame({'x': data[:,idx], 'y': meta})\n",
    "#     lm = \n",
    "    \n",
    "#     return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(doTTest(5)['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>average_impact</th>\n",
       "      <th>abs_impact</th>\n",
       "      <th>model_0</th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_2</th>\n",
       "      <th>model_3</th>\n",
       "      <th>model_4</th>\n",
       "      <th>model_5</th>\n",
       "      <th>model_6</th>\n",
       "      <th>model_7</th>\n",
       "      <th>model_8</th>\n",
       "      <th>model_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pf3D7_05_v3:425000</td>\n",
       "      <td>0.539482</td>\n",
       "      <td>0.539482</td>\n",
       "      <td>0.453976</td>\n",
       "      <td>0.542418</td>\n",
       "      <td>0.578322</td>\n",
       "      <td>0.672632</td>\n",
       "      <td>0.491159</td>\n",
       "      <td>0.469516</td>\n",
       "      <td>0.564211</td>\n",
       "      <td>0.598318</td>\n",
       "      <td>0.512342</td>\n",
       "      <td>0.511928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pf3D7_06_v3:635000</td>\n",
       "      <td>0.556075</td>\n",
       "      <td>0.556075</td>\n",
       "      <td>0.465491</td>\n",
       "      <td>0.637069</td>\n",
       "      <td>0.469721</td>\n",
       "      <td>0.620607</td>\n",
       "      <td>0.562875</td>\n",
       "      <td>0.546396</td>\n",
       "      <td>0.557477</td>\n",
       "      <td>0.570990</td>\n",
       "      <td>0.562770</td>\n",
       "      <td>0.567351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Pf3D7_13_v3:805000</td>\n",
       "      <td>0.542593</td>\n",
       "      <td>0.542593</td>\n",
       "      <td>0.466728</td>\n",
       "      <td>0.599847</td>\n",
       "      <td>0.501042</td>\n",
       "      <td>0.516853</td>\n",
       "      <td>0.500853</td>\n",
       "      <td>0.581882</td>\n",
       "      <td>0.563581</td>\n",
       "      <td>0.560515</td>\n",
       "      <td>0.515381</td>\n",
       "      <td>0.619251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Pf3D7_13_v3:1715000</td>\n",
       "      <td>0.409438</td>\n",
       "      <td>0.409438</td>\n",
       "      <td>0.370718</td>\n",
       "      <td>0.379489</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.492559</td>\n",
       "      <td>0.416885</td>\n",
       "      <td>0.432492</td>\n",
       "      <td>0.470018</td>\n",
       "      <td>0.301428</td>\n",
       "      <td>0.424113</td>\n",
       "      <td>0.498509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Pf3D7_13_v3:1725000</td>\n",
       "      <td>0.486912</td>\n",
       "      <td>0.486912</td>\n",
       "      <td>0.560584</td>\n",
       "      <td>0.509911</td>\n",
       "      <td>0.385374</td>\n",
       "      <td>0.464293</td>\n",
       "      <td>0.443939</td>\n",
       "      <td>0.501288</td>\n",
       "      <td>0.487371</td>\n",
       "      <td>0.514259</td>\n",
       "      <td>0.481353</td>\n",
       "      <td>0.520750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pf3D7_14_v3:765000</td>\n",
       "      <td>0.420293</td>\n",
       "      <td>0.420293</td>\n",
       "      <td>0.389437</td>\n",
       "      <td>0.355969</td>\n",
       "      <td>0.338384</td>\n",
       "      <td>0.360646</td>\n",
       "      <td>0.466625</td>\n",
       "      <td>0.456611</td>\n",
       "      <td>0.513232</td>\n",
       "      <td>0.415833</td>\n",
       "      <td>0.466709</td>\n",
       "      <td>0.439482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Pf3D7_14_v3:1235000</td>\n",
       "      <td>0.299846</td>\n",
       "      <td>0.299846</td>\n",
       "      <td>0.277910</td>\n",
       "      <td>0.319918</td>\n",
       "      <td>0.314440</td>\n",
       "      <td>0.342030</td>\n",
       "      <td>0.223985</td>\n",
       "      <td>0.337257</td>\n",
       "      <td>0.334390</td>\n",
       "      <td>0.227442</td>\n",
       "      <td>0.279752</td>\n",
       "      <td>0.341333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  average_impact  abs_impact   model_0   model_1  \\\n",
       "idx                                                                        \n",
       "24    Pf3D7_05_v3:425000        0.539482    0.539482  0.453976  0.542418   \n",
       "28    Pf3D7_06_v3:635000        0.556075    0.556075  0.465491  0.637069   \n",
       "79    Pf3D7_13_v3:805000        0.542593    0.542593  0.466728  0.599847   \n",
       "85   Pf3D7_13_v3:1715000        0.409438    0.409438  0.370718  0.379489   \n",
       "88   Pf3D7_13_v3:1725000        0.486912    0.486912  0.560584  0.509911   \n",
       "98    Pf3D7_14_v3:765000        0.420293    0.420293  0.389437  0.355969   \n",
       "99   Pf3D7_14_v3:1235000        0.299846    0.299846  0.277910  0.319918   \n",
       "\n",
       "      model_2   model_3   model_4   model_5   model_6   model_7   model_8  \\\n",
       "idx                                                                         \n",
       "24   0.578322  0.672632  0.491159  0.469516  0.564211  0.598318  0.512342   \n",
       "28   0.469721  0.620607  0.562875  0.546396  0.557477  0.570990  0.562770   \n",
       "79   0.501042  0.516853  0.500853  0.581882  0.563581  0.560515  0.515381   \n",
       "85   0.308174  0.492559  0.416885  0.432492  0.470018  0.301428  0.424113   \n",
       "88   0.385374  0.464293  0.443939  0.501288  0.487371  0.514259  0.481353   \n",
       "98   0.338384  0.360646  0.466625  0.456611  0.513232  0.415833  0.466709   \n",
       "99   0.314440  0.342030  0.223985  0.337257  0.334390  0.227442  0.279752   \n",
       "\n",
       "      model_9  \n",
       "idx            \n",
       "24   0.511928  \n",
       "28   0.567351  \n",
       "79   0.619251  \n",
       "85   0.498509  \n",
       "88   0.520750  \n",
       "98   0.439482  \n",
       "99   0.341333  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PF3D7_0510100:None\n",
      "PF3D7_0615400:None\n",
      "PF3D7_1319400:None,PF3D7_1319500:None\n",
      "PF3D7_1343400:RAD5\n",
      "PF3D7_1343700:Kelch13\n",
      "PF3D7_1418100:LISP1\n",
      "PF3D7_1431400:SRA,PF3D7_1431500:MAPK1\n"
     ]
    }
   ],
   "source": [
    "#search for genes\n",
    "def getChrCode(name):\n",
    "    try:\n",
    "        return re.search('_([0-9]+)_', name).group(1)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def makeReq(id):\n",
    "    chr, start = id.split(':')\n",
    "    end = int(start) + 5000\n",
    "    if getChrCode(chr):\n",
    "        url = url_template.format(getChrCode(chr), start, end)\n",
    "        res = requests.get(url)\n",
    "        try:\n",
    "#             res_list = res.json()['response']['recordset']['records'][0]['fields'][1]['value']\n",
    "\n",
    "            res_list = ['{0}:{1}'.format(x['id'].split('/')[0], str(x['fields'][1]['value'])) for x in res.json()['response']['recordset']['records']]\n",
    "            res_str = ','.join(res_list)\n",
    "            print(res_str)\n",
    "            return res_str\n",
    "        except Exception as e:\n",
    "            print('error at this one ' + str(e) + ' ' + str(res.json()))\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        print('bad chr ' + chr)\n",
    "    \n",
    "import requests, re, json\n",
    "url_template = 'https://plasmodb.org/plasmo/webservices/GeneQuestions/GenesByLocation.json?\\\n",
    "organismSinglePick=Plasmodium falciparum 3D7&\\\n",
    "chromosomeOptional={0}&\\\n",
    "start_point={1}&\\\n",
    "end_point={2}&\\\n",
    "o-fields=gene_product,gene_name'\n",
    "\n",
    "results = prediction_df['id'].map(makeReq)\n",
    "\n",
    "# # makeReq('Pf3D7_13_v3:1725000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This is the by-genes mode\n",
    "# def makeGeneReq(id):\n",
    "#     gene_id = id.split(':')[0]\n",
    "#     if gene_id.endswith('_UTR'):\n",
    "#         gene_id = gene_id[:-4]\n",
    "        \n",
    "#     url = gene_url_template.format(gene_id)\n",
    "#     res = requests.get(url)\n",
    "#     try:\n",
    "# #             res_list = res.json()['response']['recordset']['records'][0]['fields'][1]['value']\n",
    "\n",
    "#         res_list = ['{0}:{1}'.format(id, str(x['fields'][0]['value'])) for x in res.json()['response']['recordset']['records']]\n",
    "#         res_str = ','.join(res_list)\n",
    "#         print(res_str)\n",
    "#         return res_str\n",
    "#     except Exception as e:\n",
    "#         print('error at this one ' + str(e) + ' ' + str(res.json()))\n",
    "#         return None\n",
    "\n",
    "\n",
    "# import requests, re, json\n",
    "# gene_url_template = 'https://plasmodb.org/plasmo/webservices/GeneQuestions/GeneByLocusTag.json?\\\n",
    "# ds_gene_ids_data={0}&\\\n",
    "# o-fields=gene_product'\n",
    "# results = prediction_df['id'].map(makeGeneReq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id  average_impact  abs_impact   model_0   model_1  \\\n",
      "idx                                                                        \n",
      "28    Pf3D7_06_v3:635000        0.556075    0.556075  0.465491  0.637069   \n",
      "79    Pf3D7_13_v3:805000        0.542593    0.542593  0.466728  0.599847   \n",
      "24    Pf3D7_05_v3:425000        0.539482    0.539482  0.453976  0.542418   \n",
      "88   Pf3D7_13_v3:1725000        0.486912    0.486912  0.560584  0.509911   \n",
      "98    Pf3D7_14_v3:765000        0.420293    0.420293  0.389437  0.355969   \n",
      "85   Pf3D7_13_v3:1715000        0.409438    0.409438  0.370718  0.379489   \n",
      "99   Pf3D7_14_v3:1235000        0.299846    0.299846  0.277910  0.319918   \n",
      "\n",
      "      model_2   model_3   model_4   model_5   model_6   model_7   model_8  \\\n",
      "idx                                                                         \n",
      "28   0.469721  0.620607  0.562875  0.546396  0.557477  0.570990  0.562770   \n",
      "79   0.501042  0.516853  0.500853  0.581882  0.563581  0.560515  0.515381   \n",
      "24   0.578322  0.672632  0.491159  0.469516  0.564211  0.598318  0.512342   \n",
      "88   0.385374  0.464293  0.443939  0.501288  0.487371  0.514259  0.481353   \n",
      "98   0.338384  0.360646  0.466625  0.456611  0.513232  0.415833  0.466709   \n",
      "85   0.308174  0.492559  0.416885  0.432492  0.470018  0.301428  0.424113   \n",
      "99   0.314440  0.342030  0.223985  0.337257  0.334390  0.227442  0.279752   \n",
      "\n",
      "      model_9                                  genes  counts  \n",
      "idx                                                           \n",
      "28   0.567351                     PF3D7_0615400:None     8.0  \n",
      "79   0.619251  PF3D7_1319400:None,PF3D7_1319500:None     9.0  \n",
      "24   0.511928                     PF3D7_0510100:None    17.0  \n",
      "88   0.520750                  PF3D7_1343700:Kelch13    26.0  \n",
      "98   0.439482                    PF3D7_1418100:LISP1     8.0  \n",
      "85   0.498509                     PF3D7_1343400:RAD5     8.0  \n",
      "99   0.341333  PF3D7_1431400:SRA,PF3D7_1431500:MAPK1    18.0  \n"
     ]
    }
   ],
   "source": [
    "prediction_df['genes'] = results\n",
    "prediction_df['counts'] = np.sum(data, axis=0)[[int(x) for x in prediction_df.index.to_numpy()]]\n",
    "prediction_df = prediction_df.sort_values('abs_impact', ascending=False)\n",
    "print(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(out_file, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum1 = weights[0].sum(axis=1)\n",
    "# print(sum1.shape)\n",
    "# sum_df = pd.DataFrame({'sum':sum1})\n",
    "# sum_file = working_dir / 'sums.tsv'\n",
    "# sum_df.to_csv(sum_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# class fakemodel():\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "#     def predict(self, arr):\n",
    "#         return np.sum(arr, axis=1).reshape(-1, 1)\n",
    "# data = np.array([[1,0,1,0], [0,0,0,1], [1,1,1,0]])\n",
    "# z = getPredictions(fakemodel())\n",
    "# for x in z:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
