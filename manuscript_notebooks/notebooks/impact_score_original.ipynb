{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this one I'm hoping to graph out all the layers, hopefully to prove that all\n",
    "the trained models focus on a couple of specific features. We'll leave identifying\n",
    "the relevant features to maybe a different one? Or maybe it'll just happen near the end.\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import statsmodels\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import plotly.express as px\n",
    "\n",
    "working_dir = Path('/mnt/d/data/nn_scalar3/output_mod')\n",
    "# input_file = working_dir / 'saved_model0.h5'\n",
    "data_file = working_dir / 'data.tsv'\n",
    "meta_file = working_dir / 'meta.tsv'\n",
    "id_file = working_dir / 'prefilter.tsv'\n",
    "out_file = working_dir / 'predicted_genes_full_redo.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/javi/workspace/NeuralNet/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/javi/workspace/NeuralNet/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 13:49:21.748128: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2025-11-07 13:49:21.753312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3686400000 Hz\n",
      "2025-11-07 13:49:21.754537: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x577cb77f3bd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-07 13:49:21.754568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "n_models = 10\n",
    "models = [tf.keras.models.load_model((working_dir / 'saved_model{0}.h5'.format(n))) for n in range(n_models)]\n",
    "    \n",
    "\n",
    "# model1 = tf.keras.models.load_model(input_file)\n",
    "data = np.loadtxt(data_file)\n",
    "meta = np.loadtxt(meta_file)\n",
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(298, 32), (32,), (32, 16), (16,), (16, 1), (1,)]\n"
     ]
    }
   ],
   "source": [
    "weights = models[0].get_weights()\n",
    "print([x.shape for x in weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay we're just doing the prediction here\n",
    "#so the highest numbers in impact will be the selected vals\n",
    "\n",
    "def makeModSamples(sample):\n",
    "    n_features = sample.shape[0]\n",
    "    base = np.tile(sample, (n_features, 1)) #the same one repeated\n",
    "    msk = np.zeros_like(base)\n",
    "    for x in range(n_features):\n",
    "        if base[x][x] > 0:\n",
    "            base[x][x] = 0\n",
    "            msk[x,:] = 1\n",
    "\n",
    "    return np.array([base, msk]) #returns a 3D array\n",
    "    \n",
    "\n",
    "def getPredictions(model):\n",
    "    \n",
    "    def apply_fn(arr): #receives a 3D array generated by makeModSamples and reduces to two, then predict\n",
    "        preds = model.predict(arr[0])\n",
    "        return preds.reshape(-1,) * arr[1,:,0]\n",
    "\n",
    "    #here we are only counting ones above bound\n",
    "    def my_relu(n, bound):\n",
    "        if n > bound:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    #turn 1s to 0s\n",
    "    mod = np.apply_along_axis(makeModSamples, 1, data)\n",
    "    mod_preds = np.array([apply_fn(x) for x in mod]) #result should be a 2D array of samples x features\n",
    "    original_preds = model.predict(data)\n",
    "    counts = np.sum(data, axis=0)\n",
    "    \n",
    "#     print(original_preds, mod_preds)\n",
    "#     diffs = np.absolute(((mod_preds - original_preds) * (mod_preds > 0)))\n",
    "    #given that we have modded values, I'm going to try non-abs values.\n",
    "    diffs = (original_preds - mod_preds) * (np.absolute(mod_preds) > 0)\n",
    "    total_diffs = np.sum(diffs, axis=0)\n",
    "    avg_diffs = total_diffs / counts\n",
    "    \n",
    "#     print(diffs.shape, avg_diffs.shape)\n",
    "    \n",
    "    #we care about counts up to a point\n",
    "    \n",
    "    n_samples = data.shape[0]\n",
    "    bound = int(n_samples * 0.05) #that point being 5% of all samples\n",
    "#     bound = 5\n",
    "    count_modifier = np.array([my_relu(x, bound) for x in counts])\n",
    "    \n",
    "#     print(count_modifier.shape)\n",
    "    res = avg_diffs * count_modifier #this one gave the good results\n",
    "#     res = avg_diffs #here we're applying the count modifier later\n",
    "    \n",
    "#     res = np.sum(diffs, axis=0) * count_modifier\n",
    "#     print(count_modifier)\n",
    "\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we don't have to run this every time, since we saved the output in the next cell\n",
    "# impact_lists = []\n",
    "# for m in models:\n",
    "#     impact_lists.append(getPredictions(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load this!\n",
    "# np.save(\n",
    "#     working_dir / 'impact_scores_full',\n",
    "#     np.array(impact_lists)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_lists = np.load(working_dir / 'impact_scores_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_lists = [np.absolute(x) for x in impact_lists]\n",
    "ind_lists = [np.argsort(x)[::-1] for x in abs_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_hits = int(np.count_nonzero(impact_lists[0]) * 0.2) #we take top 20%\n",
    "# top_hits = [np.sort(x[:n_hits]) for x in ind_lists]\n",
    "\n",
    "# #in this case we're saying top 20% of all hits, and more than 5% representation\n",
    "# n_min = data.shape[0] * 0.05\n",
    "# features_to_use = np.argwhere(np.sum(data, axis=0) > n_min).reshape(-1,)\n",
    "# top_hits_filtered = [np.intersect1d(hits, features_to_use) for hits in top_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We're looking for an intersection between three models\n",
    "# common_inds = np.intersect1d(top_hits[0], top_hits[1])\n",
    "# for x in top_hits[2:]:\n",
    "#     common_inds = np.intersect1d(common_inds, x)\n",
    "# common_inds = np.sort(common_inds)\n",
    "\n",
    "##DELETE AFTER, this part skips the intersection and lists everything\n",
    "common_inds = [np.sort(x[:np.count_nonzero(impact_lists[0])]) for x in ind_lists][0]\n",
    "##\n",
    "# ind_list_sorted = np.matrix([np.sort(x) for x in ind_list], dtype=np.int32)\n",
    "# print(str(ind_list_sorted))\n",
    "average_impact = np.average([x[common_inds] for x in impact_lists], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_impact is the sum of the impact of each feature across all models\n",
    "total_impact = np.array(impact_lists).sum(axis=0)\n",
    "id_df = pd.read_csv(id_file, sep='\\t')\n",
    "prediction_df = pd.DataFrame({\n",
    "    'id': id_df['id'],\n",
    "    'total_impact': total_impact,\n",
    "    'abs_impact': np.absolute(total_impact)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total_impact</th>\n",
       "      <th>abs_impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pf3D7_01_v3:105000</td>\n",
       "      <td>-0.724425</td>\n",
       "      <td>0.724425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pf3D7_01_v3:180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pf3D7_01_v3:195000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pf3D7_01_v3:280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pf3D7_01_v3:315000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Pf3D7_14_v3:2480000</td>\n",
       "      <td>-1.388514</td>\n",
       "      <td>1.388514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Pf3D7_14_v3:2530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Pf3D7_14_v3:2685000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Pf3D7_14_v3:3035000</td>\n",
       "      <td>0.684280</td>\n",
       "      <td>0.684280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Pf3D7_14_v3:3095000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  total_impact  abs_impact\n",
       "0     Pf3D7_01_v3:105000     -0.724425    0.724425\n",
       "1     Pf3D7_01_v3:180000      0.000000    0.000000\n",
       "2     Pf3D7_01_v3:195000      0.000000    0.000000\n",
       "3     Pf3D7_01_v3:280000      0.000000    0.000000\n",
       "4     Pf3D7_01_v3:315000      0.000000    0.000000\n",
       "..                   ...           ...         ...\n",
       "293  Pf3D7_14_v3:2480000     -1.388514    1.388514\n",
       "294  Pf3D7_14_v3:2530000      0.000000    0.000000\n",
       "295  Pf3D7_14_v3:2685000      0.000000    0.000000\n",
       "296  Pf3D7_14_v3:3035000      0.684280    0.684280\n",
       "297  Pf3D7_14_v3:3095000      0.000000    0.000000\n",
       "\n",
       "[298 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need to search for genes here, just need to graph the total impact\n",
    "n_chr = 14\n",
    "sig_list = [1725000, 2240000, 1170000, 420000, 1695000]\n",
    "# create plotly manhattan plot of abs_impact vs id from prediction_df\n",
    "prediction_df['position'] = prediction_df.id.apply(lambda x: int(x.split(':')[-1]))\n",
    "prediction_df['chr'] = prediction_df.id.apply(lambda x: int(x.split('_')[1]))\n",
    "prediction_df['is_sig'] = prediction_df['position'].isin(sig_list)\n",
    "n_subplots = len(prediction_df['chr'].unique())\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=n_subplots,\n",
    "    subplot_titles = [f\"Chr {x}\" for x in prediction_df['chr'].unique()],\n",
    "    specs=[[{\"secondary_y\": False} for x in range(n_subplots)]],\n",
    "    horizontal_spacing=0.05\n",
    ")\n",
    "\n",
    "# px.scatter(prediction_df, x='position', y='abs_impact', color='is_sig', hover_data=['total_impact'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PF3D7_0510100:None\n",
      "PF3D7_0615400:None\n",
      "PF3D7_1319400:None,PF3D7_1319500:None\n",
      "PF3D7_1343400:RAD5\n",
      "PF3D7_1343700:Kelch13\n",
      "PF3D7_1418100:LISP1\n",
      "PF3D7_1431400:SRA,PF3D7_1431500:MAPK1\n"
     ]
    }
   ],
   "source": [
    "#search for genes\n",
    "def getChrCode(name):\n",
    "    try:\n",
    "        return re.search('_([0-9]+)_', name).group(1)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def makeReq(id):\n",
    "    chr, start = id.split(':')\n",
    "    end = int(start) + 5000\n",
    "    if getChrCode(chr):\n",
    "        url = url_template.format(getChrCode(chr), start, end)\n",
    "        res = requests.get(url)\n",
    "        try:\n",
    "#             res_list = res.json()['response']['recordset']['records'][0]['fields'][1]['value']\n",
    "\n",
    "            res_list = ['{0}:{1}'.format(x['id'].split('/')[0], str(x['fields'][1]['value'])) for x in res.json()['response']['recordset']['records']]\n",
    "            res_str = ','.join(res_list)\n",
    "            print(res_str)\n",
    "            return res_str\n",
    "        except Exception as e:\n",
    "            print('error at this one ' + str(e) + ' ' + str(res.json()))\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        print('bad chr ' + chr)\n",
    "    \n",
    "import requests, re, json\n",
    "url_template = 'https://plasmodb.org/plasmo/webservices/GeneQuestions/GenesByLocation.json?\\\n",
    "organismSinglePick=Plasmodium falciparum 3D7&\\\n",
    "chromosomeOptional={0}&\\\n",
    "start_point={1}&\\\n",
    "end_point={2}&\\\n",
    "o-fields=gene_product,gene_name'\n",
    "\n",
    "results = prediction_df['id'].map(makeReq)\n",
    "\n",
    "# # makeReq('Pf3D7_13_v3:1725000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This is the by-genes mode\n",
    "# def makeGeneReq(id):\n",
    "#     gene_id = id.split(':')[0]\n",
    "#     if gene_id.endswith('_UTR'):\n",
    "#         gene_id = gene_id[:-4]\n",
    "        \n",
    "#     url = gene_url_template.format(gene_id)\n",
    "#     res = requests.get(url)\n",
    "#     try:\n",
    "# #             res_list = res.json()['response']['recordset']['records'][0]['fields'][1]['value']\n",
    "\n",
    "#         res_list = ['{0}:{1}'.format(id, str(x['fields'][0]['value'])) for x in res.json()['response']['recordset']['records']]\n",
    "#         res_str = ','.join(res_list)\n",
    "#         print(res_str)\n",
    "#         return res_str\n",
    "#     except Exception as e:\n",
    "#         print('error at this one ' + str(e) + ' ' + str(res.json()))\n",
    "#         return None\n",
    "\n",
    "\n",
    "# import requests, re, json\n",
    "# gene_url_template = 'https://plasmodb.org/plasmo/webservices/GeneQuestions/GeneByLocusTag.json?\\\n",
    "# ds_gene_ids_data={0}&\\\n",
    "# o-fields=gene_product'\n",
    "# results = prediction_df['id'].map(makeGeneReq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id  average_impact  abs_impact   model_0   model_1  \\\n",
      "idx                                                                        \n",
      "28    Pf3D7_06_v3:635000        0.556075    0.556075  0.465491  0.637069   \n",
      "79    Pf3D7_13_v3:805000        0.542593    0.542593  0.466728  0.599847   \n",
      "24    Pf3D7_05_v3:425000        0.539482    0.539482  0.453976  0.542418   \n",
      "88   Pf3D7_13_v3:1725000        0.486912    0.486912  0.560584  0.509911   \n",
      "98    Pf3D7_14_v3:765000        0.420293    0.420293  0.389437  0.355969   \n",
      "85   Pf3D7_13_v3:1715000        0.409438    0.409438  0.370718  0.379489   \n",
      "99   Pf3D7_14_v3:1235000        0.299846    0.299846  0.277910  0.319918   \n",
      "\n",
      "      model_2   model_3   model_4   model_5   model_6   model_7   model_8  \\\n",
      "idx                                                                         \n",
      "28   0.469721  0.620607  0.562875  0.546396  0.557477  0.570990  0.562770   \n",
      "79   0.501042  0.516853  0.500853  0.581882  0.563581  0.560515  0.515381   \n",
      "24   0.578322  0.672632  0.491159  0.469516  0.564211  0.598318  0.512342   \n",
      "88   0.385374  0.464293  0.443939  0.501288  0.487371  0.514259  0.481353   \n",
      "98   0.338384  0.360646  0.466625  0.456611  0.513232  0.415833  0.466709   \n",
      "85   0.308174  0.492559  0.416885  0.432492  0.470018  0.301428  0.424113   \n",
      "99   0.314440  0.342030  0.223985  0.337257  0.334390  0.227442  0.279752   \n",
      "\n",
      "      model_9                                  genes  counts  \n",
      "idx                                                           \n",
      "28   0.567351                     PF3D7_0615400:None     8.0  \n",
      "79   0.619251  PF3D7_1319400:None,PF3D7_1319500:None     9.0  \n",
      "24   0.511928                     PF3D7_0510100:None    17.0  \n",
      "88   0.520750                  PF3D7_1343700:Kelch13    26.0  \n",
      "98   0.439482                    PF3D7_1418100:LISP1     8.0  \n",
      "85   0.498509                     PF3D7_1343400:RAD5     8.0  \n",
      "99   0.341333  PF3D7_1431400:SRA,PF3D7_1431500:MAPK1    18.0  \n"
     ]
    }
   ],
   "source": [
    "prediction_df['genes'] = results\n",
    "prediction_df['counts'] = np.sum(data, axis=0)[[int(x) for x in prediction_df.index.to_numpy()]]\n",
    "prediction_df = prediction_df.sort_values('abs_impact', ascending=False)\n",
    "print(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(out_file, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum1 = weights[0].sum(axis=1)\n",
    "# print(sum1.shape)\n",
    "# sum_df = pd.DataFrame({'sum':sum1})\n",
    "# sum_file = working_dir / 'sums.tsv'\n",
    "# sum_df.to_csv(sum_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# class fakemodel():\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "#     def predict(self, arr):\n",
    "#         return np.sum(arr, axis=1).reshape(-1, 1)\n",
    "# data = np.array([[1,0,1,0], [0,0,0,1], [1,1,1,0]])\n",
    "# z = getPredictions(fakemodel())\n",
    "# for x in z:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
