{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d3b1ec",
   "metadata": {},
   "source": [
    "we're looking to train and evaluate models using the 8-factor simulated data to add a data point without altering the original python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0acafcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43edeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net.KerasNet_backup import (\n",
    "    importData, ohe, train_test_split, trainModel, trainAEModel, prefiltering,\n",
    "    trainPrefilterModel, write_result, revOneHot, trainLasso, rmsep, \n",
    "    trainConvModel, eval_results,\n",
    ")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f411428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(data, meta):\n",
    "    # not prefiltered\n",
    "    fun_set_1 = {\n",
    "        'dense': trainModel, \n",
    "        'autoencoder': trainAEModel, \n",
    "        'convolutional': trainConvModel,\n",
    "        'lasso': trainLasso,\n",
    "    }\n",
    "    results = {}\n",
    "    for name, fun in fun_set_1.items():\n",
    "        results[name] = eval_results(\n",
    "            fun, data, meta, 10\n",
    "        )\n",
    "\n",
    "    _, filtered_data = prefiltering(data, meta)\n",
    "    fun_set_2 = {\n",
    "        'two_stage': trainPrefilterModel,\n",
    "    }\n",
    "    for name, fun in fun_set_2.items():\n",
    "        results[name] = eval_results(\n",
    "            fun, filtered_data, meta, 10\n",
    "        )\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56c69a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/javi/workspace/NeuralNet/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/javi/workspace/NeuralNet/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 01:31:21.418369: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2025-11-13 01:31:21.426832: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3686395000 Hz\n",
      "2025-11-13 01:31:21.427644: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55624e0c8650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-13 01:31:21.427668: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/javi/workspace/NeuralNet/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javi/workspace/NeuralNet/venv/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 features selected through prefiltering\n",
      "64 features selected through prefiltering\n",
      "64 features selected through prefiltering\n",
      "63 features selected through prefiltering\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.676617). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.338314). Check your callbacks.\n",
      "64 features selected through prefiltering\n",
      "62 features selected through prefiltering\n"
     ]
    }
   ],
   "source": [
    "#main runner\n",
    "in_path = Path('/mnt/d/data/popnet_paper/newsim')\n",
    "out_path = Path('/mnt/d/data/popnet_paper')\n",
    "results = []\n",
    "for n in [50,100,200,400,800,1600]:\n",
    "    df, meta_df = importData(\n",
    "        in_path / f'painting_{n}.tsv',\n",
    "        in_path / f'sim_meta_{n}.tsv',\n",
    "    )\n",
    "    data = ohe(sparse=False).fit_transform(df.to_numpy())\n",
    "    meta = meta_df.to_numpy()\n",
    "    _result = run_analysis(data, meta)\n",
    "    _result['n'] = n\n",
    "    results.append(_result)\n",
    "results_df = pd.concat(results)\n",
    "results_df.to_csv(in_path / 'sim_results_samples.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae54ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense</th>\n",
       "      <th>autoencoder</th>\n",
       "      <th>convolutional</th>\n",
       "      <th>lasso</th>\n",
       "      <th>two_stage</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.075712</td>\n",
       "      <td>0.944245</td>\n",
       "      <td>0.997614</td>\n",
       "      <td>0.913220</td>\n",
       "      <td>0.623629</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.411215</td>\n",
       "      <td>1.008823</td>\n",
       "      <td>1.933081</td>\n",
       "      <td>1.463295</td>\n",
       "      <td>0.918873</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.813400</td>\n",
       "      <td>1.350737</td>\n",
       "      <td>1.009706</td>\n",
       "      <td>4.994867</td>\n",
       "      <td>0.966993</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917952</td>\n",
       "      <td>1.025529</td>\n",
       "      <td>0.831091</td>\n",
       "      <td>0.934004</td>\n",
       "      <td>1.128933</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.391949</td>\n",
       "      <td>1.751545</td>\n",
       "      <td>1.040147</td>\n",
       "      <td>1.422340</td>\n",
       "      <td>1.704424</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.122809</td>\n",
       "      <td>0.965321</td>\n",
       "      <td>2.402740</td>\n",
       "      <td>1.806395</td>\n",
       "      <td>0.659038</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.281007</td>\n",
       "      <td>1.103029</td>\n",
       "      <td>1.503314</td>\n",
       "      <td>0.971914</td>\n",
       "      <td>0.679719</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.677115</td>\n",
       "      <td>1.000764</td>\n",
       "      <td>1.447259</td>\n",
       "      <td>0.805881</td>\n",
       "      <td>0.629207</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.078151</td>\n",
       "      <td>0.942242</td>\n",
       "      <td>1.612883</td>\n",
       "      <td>2.089631</td>\n",
       "      <td>0.679505</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.901086</td>\n",
       "      <td>2.951191</td>\n",
       "      <td>0.924199</td>\n",
       "      <td>0.932462</td>\n",
       "      <td>0.292828</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.899808</td>\n",
       "      <td>1.063645</td>\n",
       "      <td>0.766949</td>\n",
       "      <td>0.500197</td>\n",
       "      <td>0.818377</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.792142</td>\n",
       "      <td>0.912105</td>\n",
       "      <td>0.654440</td>\n",
       "      <td>0.598051</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791437</td>\n",
       "      <td>1.074028</td>\n",
       "      <td>0.737768</td>\n",
       "      <td>0.632968</td>\n",
       "      <td>0.550876</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.409863</td>\n",
       "      <td>1.331849</td>\n",
       "      <td>0.763595</td>\n",
       "      <td>0.607858</td>\n",
       "      <td>0.680846</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.887086</td>\n",
       "      <td>0.946160</td>\n",
       "      <td>0.790355</td>\n",
       "      <td>0.842784</td>\n",
       "      <td>0.869054</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.831052</td>\n",
       "      <td>1.637735</td>\n",
       "      <td>0.580803</td>\n",
       "      <td>0.617124</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.608476</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1.034851</td>\n",
       "      <td>0.606531</td>\n",
       "      <td>0.588193</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.650387</td>\n",
       "      <td>1.060507</td>\n",
       "      <td>1.118067</td>\n",
       "      <td>0.424454</td>\n",
       "      <td>0.633985</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.193236</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.943779</td>\n",
       "      <td>0.429120</td>\n",
       "      <td>0.747713</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.845869</td>\n",
       "      <td>1.033054</td>\n",
       "      <td>0.533616</td>\n",
       "      <td>0.607616</td>\n",
       "      <td>0.533716</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.610068</td>\n",
       "      <td>1.013397</td>\n",
       "      <td>0.659801</td>\n",
       "      <td>0.517359</td>\n",
       "      <td>0.474561</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.507289</td>\n",
       "      <td>0.997956</td>\n",
       "      <td>0.458395</td>\n",
       "      <td>0.353331</td>\n",
       "      <td>0.465809</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616066</td>\n",
       "      <td>1.051077</td>\n",
       "      <td>0.492503</td>\n",
       "      <td>0.389490</td>\n",
       "      <td>0.743890</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.514048</td>\n",
       "      <td>0.994458</td>\n",
       "      <td>0.682204</td>\n",
       "      <td>0.433727</td>\n",
       "      <td>0.656366</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.593911</td>\n",
       "      <td>1.053262</td>\n",
       "      <td>0.469266</td>\n",
       "      <td>1.013243</td>\n",
       "      <td>0.546229</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.671563</td>\n",
       "      <td>0.973121</td>\n",
       "      <td>0.551873</td>\n",
       "      <td>0.637643</td>\n",
       "      <td>0.561988</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.738451</td>\n",
       "      <td>0.993742</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.677036</td>\n",
       "      <td>0.624762</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.574898</td>\n",
       "      <td>1.060617</td>\n",
       "      <td>0.455780</td>\n",
       "      <td>0.443235</td>\n",
       "      <td>0.614091</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.621408</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.995782</td>\n",
       "      <td>0.514909</td>\n",
       "      <td>0.517121</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.663276</td>\n",
       "      <td>1.050419</td>\n",
       "      <td>0.675385</td>\n",
       "      <td>0.606154</td>\n",
       "      <td>0.545246</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806566</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>0.402336</td>\n",
       "      <td>0.414158</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.428097</td>\n",
       "      <td>0.876702</td>\n",
       "      <td>0.420426</td>\n",
       "      <td>0.450390</td>\n",
       "      <td>0.383108</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.599469</td>\n",
       "      <td>0.989092</td>\n",
       "      <td>0.618858</td>\n",
       "      <td>0.386448</td>\n",
       "      <td>0.480350</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.405696</td>\n",
       "      <td>0.936949</td>\n",
       "      <td>0.429589</td>\n",
       "      <td>0.365596</td>\n",
       "      <td>0.488125</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.353642</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>0.441208</td>\n",
       "      <td>0.402615</td>\n",
       "      <td>0.466506</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.614655</td>\n",
       "      <td>0.870967</td>\n",
       "      <td>0.547547</td>\n",
       "      <td>0.408276</td>\n",
       "      <td>0.406622</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.559780</td>\n",
       "      <td>0.958757</td>\n",
       "      <td>0.518449</td>\n",
       "      <td>0.393680</td>\n",
       "      <td>0.357640</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.490230</td>\n",
       "      <td>1.035822</td>\n",
       "      <td>0.507019</td>\n",
       "      <td>0.519038</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.462567</td>\n",
       "      <td>1.010355</td>\n",
       "      <td>0.477790</td>\n",
       "      <td>0.421122</td>\n",
       "      <td>0.477748</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.450473</td>\n",
       "      <td>0.942656</td>\n",
       "      <td>0.590049</td>\n",
       "      <td>0.506004</td>\n",
       "      <td>0.432853</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520311</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>0.338054</td>\n",
       "      <td>0.423056</td>\n",
       "      <td>0.396362</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.985368</td>\n",
       "      <td>0.352678</td>\n",
       "      <td>0.407293</td>\n",
       "      <td>0.426318</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666418</td>\n",
       "      <td>1.009414</td>\n",
       "      <td>0.436862</td>\n",
       "      <td>0.409602</td>\n",
       "      <td>0.343836</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.484107</td>\n",
       "      <td>0.991136</td>\n",
       "      <td>0.475792</td>\n",
       "      <td>0.410698</td>\n",
       "      <td>0.408952</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.474920</td>\n",
       "      <td>0.985270</td>\n",
       "      <td>0.383635</td>\n",
       "      <td>0.441791</td>\n",
       "      <td>0.401744</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.590670</td>\n",
       "      <td>0.957124</td>\n",
       "      <td>0.379781</td>\n",
       "      <td>0.375987</td>\n",
       "      <td>0.366971</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.566018</td>\n",
       "      <td>1.010615</td>\n",
       "      <td>0.467894</td>\n",
       "      <td>0.399859</td>\n",
       "      <td>0.390310</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.491809</td>\n",
       "      <td>0.958297</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.406611</td>\n",
       "      <td>0.502054</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.429085</td>\n",
       "      <td>1.007324</td>\n",
       "      <td>0.354404</td>\n",
       "      <td>0.367396</td>\n",
       "      <td>0.416727</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.439129</td>\n",
       "      <td>1.012875</td>\n",
       "      <td>0.437532</td>\n",
       "      <td>0.432381</td>\n",
       "      <td>0.447039</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390973</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.407893</td>\n",
       "      <td>0.373306</td>\n",
       "      <td>0.320554</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.465177</td>\n",
       "      <td>0.924340</td>\n",
       "      <td>0.394669</td>\n",
       "      <td>0.431147</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.637428</td>\n",
       "      <td>0.924667</td>\n",
       "      <td>0.387530</td>\n",
       "      <td>0.406640</td>\n",
       "      <td>0.282168</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.485902</td>\n",
       "      <td>0.935078</td>\n",
       "      <td>0.429730</td>\n",
       "      <td>0.343006</td>\n",
       "      <td>0.302636</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.390250</td>\n",
       "      <td>0.953565</td>\n",
       "      <td>0.362011</td>\n",
       "      <td>0.376995</td>\n",
       "      <td>0.308944</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.485205</td>\n",
       "      <td>0.963306</td>\n",
       "      <td>0.406234</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.278391</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.420602</td>\n",
       "      <td>1.004371</td>\n",
       "      <td>0.338841</td>\n",
       "      <td>0.383187</td>\n",
       "      <td>0.336968</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.491092</td>\n",
       "      <td>0.947226</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.391373</td>\n",
       "      <td>0.261342</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.452378</td>\n",
       "      <td>0.958821</td>\n",
       "      <td>0.386544</td>\n",
       "      <td>0.385123</td>\n",
       "      <td>0.327515</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.332119</td>\n",
       "      <td>0.948242</td>\n",
       "      <td>0.397269</td>\n",
       "      <td>0.392548</td>\n",
       "      <td>0.292729</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dense  autoencoder  convolutional     lasso  two_stage     n\n",
       "0  2.075712     0.944245       0.997614  0.913220   0.623629    50\n",
       "1  1.411215     1.008823       1.933081  1.463295   0.918873    50\n",
       "2  0.813400     1.350737       1.009706  4.994867   0.966993    50\n",
       "3  0.917952     1.025529       0.831091  0.934004   1.128933    50\n",
       "4  0.391949     1.751545       1.040147  1.422340   1.704424    50\n",
       "5  1.122809     0.965321       2.402740  1.806395   0.659038    50\n",
       "6  2.281007     1.103029       1.503314  0.971914   0.679719    50\n",
       "7  0.677115     1.000764       1.447259  0.805881   0.629207    50\n",
       "8  1.078151     0.942242       1.612883  2.089631   0.679505    50\n",
       "9  0.901086     2.951191       0.924199  0.932462   0.292828    50\n",
       "0  0.899808     1.063645       0.766949  0.500197   0.818377   100\n",
       "1  0.792142     0.912105       0.654440  0.598051   0.600357   100\n",
       "2  0.791437     1.074028       0.737768  0.632968   0.550876   100\n",
       "3  0.409863     1.331849       0.763595  0.607858   0.680846   100\n",
       "4  0.887086     0.946160       0.790355  0.842784   0.869054   100\n",
       "5  0.831052     1.637735       0.580803  0.617124   0.968000   100\n",
       "6  0.608476     0.999887       1.034851  0.606531   0.588193   100\n",
       "7  0.650387     1.060507       1.118067  0.424454   0.633985   100\n",
       "8  1.193236     0.999579       0.943779  0.429120   0.747713   100\n",
       "9  0.845869     1.033054       0.533616  0.607616   0.533716   100\n",
       "0  0.610068     1.013397       0.659801  0.517359   0.474561   200\n",
       "1  0.507289     0.997956       0.458395  0.353331   0.465809   200\n",
       "2  0.616066     1.051077       0.492503  0.389490   0.743890   200\n",
       "3  0.514048     0.994458       0.682204  0.433727   0.656366   200\n",
       "4  0.593911     1.053262       0.469266  1.013243   0.546229   200\n",
       "5  0.671563     0.973121       0.551873  0.637643   0.561988   200\n",
       "6  0.738451     0.993742       0.412400  0.677036   0.624762   200\n",
       "7  0.574898     1.060617       0.455780  0.443235   0.614091   200\n",
       "8  0.621408     0.996985       0.995782  0.514909   0.517121   200\n",
       "9  0.663276     1.050419       0.675385  0.606154   0.545246   200\n",
       "0  0.806566     0.998487       0.402336  0.414158   0.483400   400\n",
       "1  0.428097     0.876702       0.420426  0.450390   0.383108   400\n",
       "2  0.599469     0.989092       0.618858  0.386448   0.480350   400\n",
       "3  0.405696     0.936949       0.429589  0.365596   0.488125   400\n",
       "4  0.353642     0.998131       0.441208  0.402615   0.466506   400\n",
       "5  0.614655     0.870967       0.547547  0.408276   0.406622   400\n",
       "6  0.559780     0.958757       0.518449  0.393680   0.357640   400\n",
       "7  0.490230     1.035822       0.507019  0.519038   0.487345   400\n",
       "8  0.462567     1.010355       0.477790  0.421122   0.477748   400\n",
       "9  0.450473     0.942656       0.590049  0.506004   0.432853   400\n",
       "0  0.520311     0.943548       0.338054  0.423056   0.396362   800\n",
       "1  0.432990     0.985368       0.352678  0.407293   0.426318   800\n",
       "2  0.666418     1.009414       0.436862  0.409602   0.343836   800\n",
       "3  0.484107     0.991136       0.475792  0.410698   0.408952   800\n",
       "4  0.474920     0.985270       0.383635  0.441791   0.401744   800\n",
       "5  0.590670     0.957124       0.379781  0.375987   0.366971   800\n",
       "6  0.566018     1.010615       0.467894  0.399859   0.390310   800\n",
       "7  0.491809     0.958297       0.433121  0.406611   0.502054   800\n",
       "8  0.429085     1.007324       0.354404  0.367396   0.416727   800\n",
       "9  0.439129     1.012875       0.437532  0.432381   0.447039   800\n",
       "0  0.390973     0.999394       0.407893  0.373306   0.320554  1600\n",
       "1  0.465177     0.924340       0.394669  0.431147   0.313225  1600\n",
       "2  0.637428     0.924667       0.387530  0.406640   0.282168  1600\n",
       "3  0.485902     0.935078       0.429730  0.343006   0.302636  1600\n",
       "4  0.390250     0.953565       0.362011  0.376995   0.308944  1600\n",
       "5  0.485205     0.963306       0.406234  0.356198   0.278391  1600\n",
       "6  0.420602     1.004371       0.338841  0.383187   0.336968  1600\n",
       "7  0.491092     0.947226       0.358100  0.391373   0.261342  1600\n",
       "8  0.452378     0.958821       0.386544  0.385123   0.327515  1600\n",
       "9  0.332119     0.948242       0.397269  0.392548   0.292729  1600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b9301d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">dense</th>\n",
       "      <th colspan=\"2\" halign=\"left\">autoencoder</th>\n",
       "      <th colspan=\"2\" halign=\"left\">convolutional</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lasso</th>\n",
       "      <th colspan=\"2\" halign=\"left\">two_stage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.167040</td>\n",
       "      <td>0.599511</td>\n",
       "      <td>1.304343</td>\n",
       "      <td>0.631377</td>\n",
       "      <td>1.370204</td>\n",
       "      <td>0.509116</td>\n",
       "      <td>1.633401</td>\n",
       "      <td>1.257533</td>\n",
       "      <td>0.828315</td>\n",
       "      <td>0.383918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.790936</td>\n",
       "      <td>0.207052</td>\n",
       "      <td>1.105855</td>\n",
       "      <td>0.218501</td>\n",
       "      <td>0.792422</td>\n",
       "      <td>0.189443</td>\n",
       "      <td>0.586670</td>\n",
       "      <td>0.119578</td>\n",
       "      <td>0.699112</td>\n",
       "      <td>0.146715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.611098</td>\n",
       "      <td>0.070341</td>\n",
       "      <td>1.018503</td>\n",
       "      <td>0.032013</td>\n",
       "      <td>0.585339</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.192204</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.085889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.517117</td>\n",
       "      <td>0.132119</td>\n",
       "      <td>0.961792</td>\n",
       "      <td>0.055511</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>0.426733</td>\n",
       "      <td>0.050474</td>\n",
       "      <td>0.446370</td>\n",
       "      <td>0.048277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.509546</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>0.405975</td>\n",
       "      <td>0.050215</td>\n",
       "      <td>0.407467</td>\n",
       "      <td>0.022882</td>\n",
       "      <td>0.410031</td>\n",
       "      <td>0.043499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>0.455113</td>\n",
       "      <td>0.082419</td>\n",
       "      <td>0.955901</td>\n",
       "      <td>0.027586</td>\n",
       "      <td>0.386882</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>0.383952</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.302447</td>\n",
       "      <td>0.023759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dense           autoencoder           convolutional            \\\n",
       "          mean       std        mean       std          mean       std   \n",
       "n                                                                        \n",
       "50    1.167040  0.599511    1.304343  0.631377      1.370204  0.509116   \n",
       "100   0.790936  0.207052    1.105855  0.218501      0.792422  0.189443   \n",
       "200   0.611098  0.070341    1.018503  0.032013      0.585339  0.175600   \n",
       "400   0.517117  0.132119    0.961792  0.055511      0.495327  0.074121   \n",
       "800   0.509546  0.077423    0.986097  0.025302      0.405975  0.050215   \n",
       "1600  0.455113  0.082419    0.955901  0.027586      0.386882  0.027031   \n",
       "\n",
       "         lasso           two_stage            \n",
       "          mean       std      mean       std  \n",
       "n                                             \n",
       "50    1.633401  1.257533  0.828315  0.383918  \n",
       "100   0.586670  0.119578  0.699112  0.146715  \n",
       "200   0.558613  0.192204  0.575006  0.085889  \n",
       "400   0.426733  0.050474  0.446370  0.048277  \n",
       "800   0.407467  0.022882  0.410031  0.043499  \n",
       "1600  0.383952  0.024679  0.302447  0.023759  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby('n').agg(['mean', 'std'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
